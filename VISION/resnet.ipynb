{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y9t5LhudA8WZ"
   },
   "source": [
    "## ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "75rOrPh7ztTm",
    "outputId": "91dedec3-73f7-4f11-c865-12ba423b7cf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/deepvision-class/starter-code\n",
      "  Cloning https://github.com/deepvision-class/starter-code to /tmp/pip-req-build-0_cevplb\n",
      "  Running command git clone -q https://github.com/deepvision-class/starter-code /tmp/pip-req-build-0_cevplb\n",
      "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (from Colab-Utils==0.1.dev0) (1.3.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive->Colab-Utils==0.1.dev0) (1.7.12)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive->Colab-Utils==0.1.dev0) (4.1.3)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive->Colab-Utils==0.1.dev0) (3.13)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (0.17.4)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (1.15.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (0.0.4)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (3.0.1)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (1.17.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive->Colab-Utils==0.1.dev0) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive->Colab-Utils==0.1.dev0) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive->Colab-Utils==0.1.dev0) (4.6)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (50.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive->Colab-Utils==0.1.dev0) (4.1.1)\n",
      "Building wheels for collected packages: Colab-Utils\n",
      "  Building wheel for Colab-Utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Colab-Utils: filename=Colab_Utils-0.1.dev0-cp36-none-any.whl size=10324 sha256=db26751e6dc17367109fda586f505b9e2bb8dbdc6d397ced98cd637992a1ed7e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sn9pb3_v/wheels/63/d1/27/a208931527abb98d326d00209f46c80c9d745851d6a1defd10\n",
      "Successfully built Colab-Utils\n",
      "Installing collected packages: Colab-Utils\n",
      "Successfully installed Colab-Utils-0.1.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/deepvision-class/starter-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXeFpHsFxxIR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import coutils\n",
    "from coutils import fix_random_seed\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oA1f1nDhxxFA",
    "outputId": "239c6964-9794-4831-d967-f524f7ad2d80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "ltype = torch.long\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZsjFsrVBDLr"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "referenced_widgets": [
      "2b1fe752d58644c98726c67084f9f649",
      "121a77b4f103431f93214c680fc22bf5",
      "f1dd0728ce494056b3938c4339aae70c",
      "120fb2b501094ea38ca93767f43289ae",
      "bcaa6bee99ab4ab4b4adac9292a39f3a",
      "af88b76047e54444a819a4d6dc4d3d61",
      "806c37689aa74f498a2458e2b28eaa3e",
      "9196a279876e4981bfb9528083be4173"
     ]
    },
    "colab_type": "code",
    "id": "Wbt-5o4WxxN5",
    "outputId": "4aa744dd-e7aa-438a-a980-15318ab1a8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1fe752d58644c98726c67084f9f649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJkEDlxzx8D2"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "  if loader.dataset.train:\n",
    "    print('Checking accuracy on validation set')\n",
    "  else:\n",
    "    print('Checking accuracy on test set')   \n",
    "  num_correct = 0\n",
    "  num_samples = 0\n",
    "  model.eval()  # set model to evaluation mode\n",
    "  with torch.no_grad():\n",
    "    for x, y in loader:\n",
    "      x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "      y = y.to(device=device, dtype=ltype)\n",
    "      scores = model(x)\n",
    "      _, preds = scores.max(dim=1)\n",
    "      num_correct += (preds == y).sum()\n",
    "      num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QBpwRFP0WL7"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lrd, epoch, schedule):\n",
    "  \"\"\"\n",
    "  Multiply lrd to the learning rate if epoch is in schedule\n",
    "  \n",
    "  Inputs:\n",
    "  - optimizer: An Optimizer object we will use to train the model\n",
    "  - lrd: learning rate decay; a factor multiplied at scheduled epochs\n",
    "  - epochs: the current epoch number\n",
    "  - schedule: the list of epochs that requires learning rate update\n",
    "  \n",
    "  Returns: Nothing, but learning rate might be updated\n",
    "  \"\"\"\n",
    "  if epoch in schedule:\n",
    "    for param_group in optimizer.param_groups:\n",
    "      print('lr decay from {} to {}'.format(param_group['lr'], param_group['lr'] * lrd))\n",
    "      param_group['lr'] *= lrd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, epochs=1, learning_rate_decay=.1, schedule=[]\n",
    "                                                                  , verbose=True):\n",
    "  model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "  num_iters = epochs * len(loader_train)\n",
    "  if verbose:\n",
    "    num_prints = num_iters // print_every + 1\n",
    "  else:\n",
    "    num_prints = epochs\n",
    "  acc_history = torch.zeros(num_prints, dtype=torch.float)\n",
    "  iter_history = torch.zeros(num_prints, dtype=torch.long)\n",
    "  # for each epoch\n",
    "  for e in range(epochs):\n",
    "    \n",
    "    adjust_learning_rate(optimizer, learning_rate_decay, e, schedule)\n",
    "    \n",
    "    # for every minibatch\n",
    "    for t, (x, y) in enumerate(loader_train):\n",
    "      model.train()  # put model to training mode\n",
    "      x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "      y = y.to(device=device, dtype=ltype)\n",
    "\n",
    "      scores = model(x)\n",
    "      loss = F.cross_entropy(scores, y)\n",
    "\n",
    "      # Zero out all of the gradients for the variables which the optimizer\n",
    "      # will update.\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # This is the backwards pass: compute the gradient of the loss with\n",
    "      # respect to each  parameter of the model.\n",
    "      loss.backward()\n",
    "\n",
    "      # Actually update the parameters of the model using the gradients\n",
    "      # computed by the backwards pass.\n",
    "      optimizer.step()\n",
    "\n",
    "      # 화면 출력\n",
    "      tt = t + e * len(loader_train)\n",
    "\n",
    "      if verbose and (tt % print_every == 0 or (e == epochs-1 and t == len(loader_train)-1)):\n",
    "        print('Epoch %d, Iteration %d, loss = %.4f' % (e, tt, loss.item()))\n",
    "        acc = check_accuracy(loader_val, model)\n",
    "        acc_history[tt // print_every] = acc\n",
    "        iter_history[tt // print_every] = tt\n",
    "        print()\n",
    "      elif not verbose and (t == len(loader_train)-1):\n",
    "        print('Epoch %d, Iteration %d, loss = %.4f' % (e, tt, loss.item()))\n",
    "        acc = check_accuracy(loader_val, model)\n",
    "        acc_history[e] = acc\n",
    "        iter_history[e] = tt\n",
    "        print()\n",
    "  return acc_history, iter_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQwViSIv0cAw"
   },
   "source": [
    "### Plain block\n",
    "residual connection이 없는 plain block을 먼저 구현해봅니다! \n",
    "PreResNet은 Conv 레이어 전에 BatchNorm과 ReLU를 먼저 끼워넣는 순서입니다. 그래서 PreResNet이름은 pre-activation architecture에서 온 것입니다. downsampling을 위해서 maapool 레이어를 넣는 대신 block의 첫번째 Conv 레이어에서 stride를 2로 설정합니다.\n",
    "\n",
    "plain block은 shape가 $C_{in} \\times H_{in} \\times W_{out}$ 인 feature map을 받아서 shape가 $C_{out} \\times H_{out} \\times W_{out}$인 feature map을 생성합니다. block이 downsampling을 수행할 경우 $W_{out}=W_{in}/2$, $H_{out}=H_{in}/2$ 가 되고, 그렇지 않을 경우 $H_{out}=H_{in}$, $W_{out}=W_{in}$ 일 것입니다. \n",
    "\n",
    "* plain block의 레이어 구성\n",
    "1. Spatial Batch normalization\n",
    "2. ReLU\n",
    "3. Conv layer with Cout 3x3 filters, zero-padding of 1, stride 1 (downsampling할 경우 stride 2)\n",
    "4. Spatial Batch normalization\n",
    "5. ReLU\n",
    "6. Conv layer with Cout 3x3 filters, zero-padding of 1, stride 1 (downsampling할 경우 stride 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzjPzY5d0XlH"
   },
   "outputs": [],
   "source": [
    "class PlainBlock(nn.Module):\n",
    "  def __init__(self, Cin, Cout, downsample=False):\n",
    "    super().__init__()\n",
    "\n",
    "    self.net = None\n",
    "    self.net = nn.Sequential(nn.BatchNorm2d(Cin),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Conv2d(Cin, Cout, 3, padding=1, stride=2 if downsample else 1),\n",
    "                          nn.BatchNorm2d(Cout),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Conv2d(Cout, Cout, 3, padding=1))  \n",
    "  def forward(self, x):\n",
    "    return self.net(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "3RdiJgAG0XhX",
    "outputId": "04deea72-33da-49a5-acd7-7c6ff4197d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of PlainBlock without downsampling has a *correct* dimension!\n",
      "The output of PlainBlock with downsampling has a *correct* dimension!\n"
     ]
    }
   ],
   "source": [
    "### dimension check code\n",
    "data = torch.zeros(2, 3, 5, 6)\n",
    "model = PlainBlock(3, 10)\n",
    "if list(model(data).shape) == [2, 10, 5, 6]:\n",
    "  print('The output of PlainBlock without downsampling has a *correct* dimension!')\n",
    "else:\n",
    "  print('The output of PlainBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))\n",
    "\n",
    "data = torch.zeros(2, 3, 5, 6)\n",
    "model = PlainBlock(3, 10, downsample=True)\n",
    "if list(model(data).shape) == [2, 10, 3, 3]:\n",
    "  print('The output of PlainBlock with downsampling has a *correct* dimension!')\n",
    "else:\n",
    "  print('The output of PlainBlock with downsampling has an *incorrect* dimension! expected:', [2, 10, 3, 3], 'got:', list(model(data).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CuqzZQTc8Y5v"
   },
   "source": [
    "### Residual Block\n",
    "Residual block은 plain block에서 residual connection을 더한 것이라고 발표에서 말씀드렸죠? $\\mathcal{F}$ 가 plain block이고 $\\mathcal{H}$ 가 plain block의 residual version이라고 하면 $\\mathcal{F}$ 는\n",
    "\n",
    "$\\mathcal{H}(x) = \\mathcal{F}(x) + x$\n",
    "\n",
    "입니다.\n",
    "\n",
    "하지만 이 식은 plain block $\\mathcal{F}(x)$ 의 output이 input $x$ 와 동일한 shape일 경우입니다. 위의 plain block 구현에서 알 수 있듯, output이 input과 shape이 달라지는 경우를 두 가지로 생각해 볼 수 있습니다.\n",
    "  1. output channel수 $C_{out}$ 가 input channel수 $C_{in}$과 다름\n",
    "  2. plain block $\\mathcal{F}$ 가 spatial downsampling을 수행했을 때\n",
    "\n",
    "따라서 두 가지 케이스를 일반화하기 위해 shortcut connection $\\mathcal{G}$ 를 추가하겠습니다.\n",
    "\n",
    "$\\mathcal{R}(x) = \\mathcal{F}(x) + \\mathcal{G}(x)$\n",
    "\n",
    "그럼 $\\mathcal{G}$ 는 세 가지의 경우가 있습니다.\n",
    "\n",
    "1. $C_{in}=C_{out}$ 일 때\n",
    "\n",
    "    : $\\mathcal{F}$가 downsampling을 하지 않을 것이므로 $\\mathcal{F}(x)$ 와 $x$의 shape이 같을 것\n",
    "\n",
    "    :  $\\mathcal{G}$ 는 Identity function:   $\\mathcal{G}(x) = x$\n",
    "\n",
    "2. $C_{in} \\neq C_{out}$ && $\\mathcal{F}$ 가 downsampling 하지 않았을 때\n",
    "\n",
    "    : $\\mathcal{G}$ 는 1X1 conv, $C_{out}$ filters, stride 1\n",
    "\n",
    "3. $\\mathcal{F}$ 가 downsampling\n",
    "\n",
    "  : $\\mathcal{G}$ 는 1X1 conv, $C_{out}$ filters, stride 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IQDI69u80XeA"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, Cin, Cout, downsample=False):\n",
    "    super().__init__()\n",
    "\n",
    "    self.block = None # F\n",
    "    self.shortcut = None # G\n",
    "    self.block = PlainBlock(Cin, Cout, downsample)\n",
    "    if downsample:\n",
    "      self.shortcut = nn.Conv2d(Cin, Cout, 1, padding = 0, stride = 2)\n",
    "    else:\n",
    "      if Cin == Cout:\n",
    "        self.shortcut = nn.Identity()\n",
    "      else:\n",
    "        self.shortcut = nn.Conv2d(Cin, Cout, 1, padding = 0)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.block(x) + self.shortcut(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Zd_xclNY0XYu",
    "outputId": "e7e30457-4900-4205-f803-6123b858467f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of ResidualBlock without downsampling has a *correct* dimension!\n",
      "The output of ResidualBlock with downsampling has a *correct* dimension!\n"
     ]
    }
   ],
   "source": [
    "data = torch.zeros(2, 3, 5, 6)\n",
    "model = ResidualBlock(3, 10)\n",
    "if list(model(data).shape) == [2, 10, 5, 6]:\n",
    "  print('The output of ResidualBlock without downsampling has a *correct* dimension!')\n",
    "else:\n",
    "  print('The output of ResidualBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))\n",
    "\n",
    "data = torch.zeros(2, 3, 5, 6)\n",
    "model = ResidualBlock(3, 10, downsample=True)\n",
    "if list(model(data).shape) == [2, 10, 3, 3]:\n",
    "  print('The output of ResidualBlock with downsampling has a *correct* dimension!')\n",
    "else:\n",
    "  print('The output of ResidualBlock with downsampling has an *incorrect* dimension! expected:', [2, 10, 3, 3], 'got:', list(model(data).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0mDkUUAFCNDZ"
   },
   "source": [
    "### Residual stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlkUvcMK0XVg"
   },
   "outputs": [],
   "source": [
    "class ResNetStage(nn.Module):\n",
    "  def __init__(self, Cin, Cout, num_blocks, downsample=True,\n",
    "               block=ResidualBlock):\n",
    "    super().__init__()\n",
    "    blocks = [block(Cin, Cout, downsample)] # 첫번째 block에서 한번 다운샘플 하고\n",
    "    for _ in range(num_blocks - 1):         # num_block - 1 개만큼 쌓음\n",
    "      blocks.append(block(Cout, Cout))\n",
    "    self.net = nn.Sequential(*blocks)       \n",
    "      # *blocks 앞의 별표(*)는 리스트를 unpacking하는 역할 \n",
    "      # 참조: https://mingrammer.com/understanding-the-asterisk-of-python/\n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2PFePsBb0XSI",
    "outputId": "1507ba05-b4b8-45ca-fbe8-a214650678e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain block stage:\n",
      "ResNetStage(\n",
      "  (net): Sequential(\n",
      "    (0): PlainBlock(\n",
      "      (net): Sequential(\n",
      "        (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): PlainBlock(\n",
      "      (net): Sequential(\n",
      "        (0): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU()\n",
      "        (5): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Residual block stage:\n",
      "ResNetStage(\n",
      "  (net): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (block): PlainBlock(\n",
      "        (net): Sequential(\n",
      "          (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Conv2d(3, 4, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (block): PlainBlock(\n",
      "        (net): Sequential(\n",
      "          (0): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### 이제 만든 plain block과 residual block들을 stage로 만들어서 뽑아봅시다!\n",
    "print('Plain block stage:')\n",
    "print(ResNetStage(3, 4, 2, block=PlainBlock))\n",
    "print('Residual block stage:')\n",
    "print(ResNetStage(3, 4, 2, block=ResidualBlock))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Guxamz4rDM8w"
   },
   "source": [
    "### Residual stem\n",
    "stem layer는 네트워크가 시작할때 채널 수는 증가시키고 다른 dimension들은 유지할 때 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jA1qsa9n0XPN"
   },
   "outputs": [],
   "source": [
    "class ResNetStem(nn.Module):\n",
    "  def __init__(self, Cin=3, Cout=8):\n",
    "    super().__init__()\n",
    "    layers = [\n",
    "        nn.Conv2d(Cin, Cout, kernel_size=3, padding=1, stride=1),\n",
    "        nn.ReLU(),\n",
    "    ]\n",
    "    self.net = nn.Sequential(*layers)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pHu2oV6jy47l",
    "outputId": "5726d7f5-f7a1-4c38-f7c0-5fd781b55be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of ResidualBlock without downsampling has a *correct* dimension!\n"
     ]
    }
   ],
   "source": [
    "# dimention check\n",
    "data = torch.zeros(2, 3, 5, 6)\n",
    "model = ResNetStem(3, 10)\n",
    "if list(model(data).shape) == [2, 10, 5, 6]:\n",
    "  print('The output of ResidualBlock without downsampling has a *correct* dimension!')\n",
    "else:\n",
    "  print('The output of ResidualBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_qcY89mDptJ"
   },
   "source": [
    "### ResNet class\n",
    "이제 block들을 이용해서 resnet class를 만듭니다!\n",
    "\n",
    "networks : 미리 stage를 구체화해논 것! get_resnet(key) 하면 key에 해당하는 모델을 반환합니다. 예를 들어 get_resnet('resnet32') 를 하면 32 layer의 ResNet을 반환합니다.\n",
    "\n",
    "'stahe_args' key에 해당하는 value는 tuple의 형태로, 각 tuple은 (num_in_channels, num_out_channels, num_blocks, whether_do_downsample) 입니다.\n",
    "\n",
    "input size의 영향을 받지 않기 위해 conv 부분의 끝에 average pooling을 적용합니다. 따라서 linear layer에 들어가는 input sizze는 항상 (batch_size, stage_arg[-1][1]) 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAVrAYGiYx3d"
   },
   "outputs": [],
   "source": [
    "# network example\n",
    "networks = {\n",
    "  'plain32': {\n",
    "    'block': PlainBlock,\n",
    "    'stage_args': [\n",
    "      (8, 8, 5, False),\n",
    "      (8, 16, 5, True),\n",
    "      (16, 32, 5, True),\n",
    "    ]\n",
    "  },\n",
    "  'resnet32': {\n",
    "    'block': ResidualBlock,\n",
    "    'stage_args': [\n",
    "      (8, 8, 5, False),\n",
    "      (8, 16, 5, True),\n",
    "      (16, 32, 5, True),\n",
    "    ]\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUIwZE7UYyUZ"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "  def __init__(self, stage_args, Cin=3, block=ResidualBlock, num_classes=10):\n",
    "    super().__init__()\n",
    "\n",
    "    self.cnn = None\n",
    "    # ResNetStem, ResNetStage을 이용해서 conv 파트 구현하고 nn.Sequential 모듈로 감싸기\n",
    "    # 모델을 self.cnn에 저장                                             \n",
    "    layers = []\n",
    "    layers.append(ResNetStem(Cin, stage_args[0][0]))\n",
    "    for i in range (len(stage_args)):\n",
    "      layers.append(ResNetStage(*stage_args[i])) \n",
    "    self.cnn = nn.Sequential(*layers)\n",
    "    self.fc = nn.Linear(stage_args[-1][1], num_classes)\n",
    "  \n",
    "  # ResNet의 forward function 구현\n",
    "  # scores에 output 저장\n",
    "  def forward(self, x):\n",
    "    scores = None\n",
    "    x = self.cnn(x)\n",
    "    x = nn.AvgPool2d(x.shape[2])(x)\n",
    "    x = x.flatten(start_dim=1, end_dim=-1)\n",
    "    scores = self.fc(x)\n",
    "    return scores\n",
    "\n",
    "def get_resnet(name):\n",
    "  return ResNet(**networks[name])\n",
    "# **networks[name] 앞의 쌍별표(**)는 튜플을 unpacking하는 역할 \n",
    "# 참조: https://mingrammer.com/understanding-the-asterisk-of-python/    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tRAf4MVY0Oj"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VtxcvhD65OLl",
    "outputId": "a8c41843-2b07-4d96-c817-6c5050d70aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain32 \n",
      "\n",
      "Epoch 0, Iteration 765, loss = 1.1885\n",
      "Checking accuracy on validation set\n",
      "Got 574 / 1000 correct (57.40)\n",
      "\n",
      "Epoch 1, Iteration 1531, loss = 1.1080\n",
      "Checking accuracy on validation set\n",
      "Got 548 / 1000 correct (54.80)\n",
      "\n",
      "Epoch 2, Iteration 2297, loss = 1.0254\n",
      "Checking accuracy on validation set\n",
      "Got 658 / 1000 correct (65.80)\n",
      "\n",
      "Epoch 3, Iteration 3063, loss = 0.4737\n",
      "Checking accuracy on validation set\n",
      "Got 696 / 1000 correct (69.60)\n",
      "\n",
      "Epoch 4, Iteration 3829, loss = 0.5694\n",
      "Checking accuracy on validation set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "\n",
      "Epoch 5, Iteration 4595, loss = 0.8150\n",
      "Checking accuracy on validation set\n",
      "Got 743 / 1000 correct (74.30)\n",
      "\n",
      "lr decay from 0.01 to 0.001\n",
      "Epoch 6, Iteration 5361, loss = 0.6112\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "\n",
      "Epoch 7, Iteration 6127, loss = 0.4992\n",
      "Checking accuracy on validation set\n",
      "Got 806 / 1000 correct (80.60)\n",
      "\n",
      "lr decay from 0.001 to 0.0001\n",
      "Epoch 8, Iteration 6893, loss = 0.5738\n",
      "Checking accuracy on validation set\n",
      "Got 809 / 1000 correct (80.90)\n",
      "\n",
      "Epoch 9, Iteration 7659, loss = 0.5163\n",
      "Checking accuracy on validation set\n",
      "Got 808 / 1000 correct (80.80)\n",
      "\n",
      "resnet32 \n",
      "\n",
      "Epoch 0, Iteration 765, loss = 1.0894\n",
      "Checking accuracy on validation set\n",
      "Got 573 / 1000 correct (57.30)\n",
      "\n",
      "Epoch 1, Iteration 1531, loss = 1.2593\n",
      "Checking accuracy on validation set\n",
      "Got 569 / 1000 correct (56.90)\n",
      "\n",
      "Epoch 2, Iteration 2297, loss = 0.8367\n",
      "Checking accuracy on validation set\n",
      "Got 626 / 1000 correct (62.60)\n",
      "\n",
      "Epoch 3, Iteration 3063, loss = 0.7157\n",
      "Checking accuracy on validation set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "\n",
      "Epoch 4, Iteration 3829, loss = 0.7631\n",
      "Checking accuracy on validation set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "\n",
      "Epoch 5, Iteration 4595, loss = 0.7075\n",
      "Checking accuracy on validation set\n",
      "Got 731 / 1000 correct (73.10)\n",
      "\n",
      "lr decay from 0.01 to 0.001\n",
      "Epoch 6, Iteration 5361, loss = 0.5857\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "\n",
      "Epoch 7, Iteration 6127, loss = 0.5057\n",
      "Checking accuracy on validation set\n",
      "Got 804 / 1000 correct (80.40)\n",
      "\n",
      "lr decay from 0.001 to 0.0001\n",
      "Epoch 8, Iteration 6893, loss = 0.5557\n",
      "Checking accuracy on validation set\n",
      "Got 815 / 1000 correct (81.50)\n",
      "\n",
      "Epoch 9, Iteration 7659, loss = 0.4869\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['plain32', 'resnet32']\n",
    "acc_history_dict = {}\n",
    "iter_history_dict = {}\n",
    "for name in names:\n",
    "  fix_random_seed(0)\n",
    "  print(name, '\\n')\n",
    "  model = get_resnet(name)\n",
    "#   init_module(model)\n",
    "  \n",
    "  optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=.9, weight_decay=1e-4)\n",
    "\n",
    "  acc_history, iter_history = train(model, optimizer, epochs=10, schedule=[6, 8], verbose=False)\n",
    "  acc_history_dict[name] = acc_history\n",
    "  iter_history_dict[name] = iter_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsVFw9PHbqBU"
   },
   "source": [
    "### Residual bottleneck block\n",
    "bottleneck block은 연산량을 줄이면서 input을 더 많이 가공할 수 있기 때문에(더 깊은 레이어를 거침) 효율적입니다!\n",
    "\n",
    "bottleneck block의 레이어는 다음과 같습니다.\n",
    "\n",
    "1. Spatial Batch normalization\n",
    "2. ReLU\n",
    "3. Convolutional layer with `Cout // 4` 1x1 filters, stride 2 if downsampling; otherwise stride 1\n",
    "4. Spatial Batch normalization\n",
    "5. ReLU\n",
    "6. Convolutional layer with `Cout // 4` 3x3 filters, with zero-padding of 1\n",
    "7. Spatial Batch normalization\n",
    "8. ReLU\n",
    "9. Convolutional layer with `Cout` 1x1 filters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dL7x1JThcr1O"
   },
   "outputs": [],
   "source": [
    "class ResidualBottleneckBlock(nn.Module):\n",
    "  def __init__(self, Cin, Cout, downsample=False):\n",
    "    super().__init__()\n",
    "\n",
    "    self.block = None\n",
    "    self.shortcut = None\n",
    "\n",
    "    self.block = nn.Sequential(nn.BatchNorm2d(Cin),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(Cin, Cout//4, 1, stride=2 if downsample else 1),\n",
    "                               nn.BatchNorm2d(Cout//4),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(Cout//4, Cout//4, 3, padding=1),\n",
    "                               nn.BatchNorm2d(Cout//4),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(Cout//4, Cout, 1))\n",
    "    if downsample:\n",
    "      self.shortcut = nn.Conv2d(Cin, Cout, 1, padding = 0, stride = 2)\n",
    "    else:\n",
    "      if Cin == Cout:\n",
    "        self.shortcut = nn.Identity()\n",
    "      else:\n",
    "        self.shortcut = nn.Conv2d(Cin, Cout, 1, padding = 0)\n",
    "    \n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.block(x) + self.shortcut(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "YdT6lJoYieq0",
    "outputId": "a901298f-9683-4d25-853a-62c5c3a4d55d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of ResidualBlock without downsampling has a *correct* dimension!\n",
      "The output of ResidualBlock with downsampling has a *correct* dimension!\n"
     ]
    }
   ],
   "source": [
    "# dimension check\n",
    "data = torch.zeros(2, 3, 5, 6)\n",
    "model = ResidualBottleneckBlock(3, 10)\n",
    "if list(model(data).shape) == [2, 10, 5, 6]:\n",
    "  print('The output of ResidualBlock without downsampling has a *correct* dimension!')\n",
    "else:\n",
    "  print('The output of ResidualBlock without downsampling has an *incorrect* dimension! expected:', [2, 10, 5, 6], 'got:', list(model(data).shape))\n",
    "\n",
    "data = torch.zeros(2, 3, 5, 6)\n",
    "model = ResidualBottleneckBlock(3, 10, downsample=True)\n",
    "if list(model(data).shape) == [2, 10, 3, 3]:\n",
    "  print('The output of ResidualBlock with downsampling has a *correct* dimension!')\n",
    "else:\n",
    "  print('The output of ResidualBlock with downsampling has an *incorrect* dimension! expected:', [2, 10, 3, 3], 'got:', list(model(data).shape))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "120fb2b501094ea38ca93767f43289ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9196a279876e4981bfb9528083be4173",
      "placeholder": "​",
      "style": "IPY_MODEL_806c37689aa74f498a2458e2b28eaa3e",
      "value": " 170500096/? [00:20&lt;00:00, 33521021.26it/s]"
     }
    },
    "121a77b4f103431f93214c680fc22bf5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b1fe752d58644c98726c67084f9f649": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1dd0728ce494056b3938c4339aae70c",
       "IPY_MODEL_120fb2b501094ea38ca93767f43289ae"
      ],
      "layout": "IPY_MODEL_121a77b4f103431f93214c680fc22bf5"
     }
    },
    "806c37689aa74f498a2458e2b28eaa3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9196a279876e4981bfb9528083be4173": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af88b76047e54444a819a4d6dc4d3d61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcaa6bee99ab4ab4b4adac9292a39f3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1dd0728ce494056b3938c4339aae70c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af88b76047e54444a819a4d6dc4d3d61",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bcaa6bee99ab4ab4b4adac9292a39f3a",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
